{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This lab focuses on the \"Design Mastery\" and \"Complex Solving\" learning outcomes from Module 5.\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 1: Markdown]**\n",
        "\n",
        "# **Module 5 Lab: Mastering Prompt Engineering**\n",
        "\n",
        "**Objective:** Learn to design reliable, business-grade prompts using Structure, Chain-of-Thought (CoT), and ReAct frameworks.\n",
        "\n",
        "**What You Will Learn:**\n",
        "\n",
        "1.\n",
        "**Structure:** Mastering the 4-part prompt framework .\n",
        "\n",
        "\n",
        "2.\n",
        "**Reasoning:** Implementing Chain-of-Thought (CoT) for accuracy.\n",
        "\n",
        "\n",
        "3.\n",
        "**Patterning:** Using Few-Shot examples for consistent outputs.\n",
        "\n",
        "\n",
        "4.\n",
        "**Agentic Design:** structuring ReAct prompts for autonomous agents.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 2: Code]**"
      ],
      "metadata": {
        "id": "qVIN2QaSQgR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup: Define Helper Function\n",
        "# We will use this simple function to print our structured prompts clearly.\n",
        "# In a real scenario, you would pass the 'final_prompt' variable to an API (like OpenAI or Gemini).\n",
        "\n",
        "def display_prompt(title, prompt_content):\n",
        "    print(f\"--- {title} ---\")\n",
        "    print(prompt_content)\n",
        "    print(\"-\" * 30)\n",
        "    print(\"âœ… Ready to copy-paste into an LLM!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Z_kxLM5YQgSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **[Cell 3: Markdown]**\n",
        "\n",
        "## **Exercise 1: The Perfect Prompt Structure**\n",
        "\n",
        "**Goal:** Move away from vague questions to structured instructions using the 4-part framework .\n",
        "\n",
        "A robust prompt consists of:\n",
        "\n",
        "1.\n",
        "**Instruction:** What specifically to do (Active verbs).\n",
        "\n",
        "\n",
        "2.\n",
        "**Context:** The role or background info.\n",
        "\n",
        "\n",
        "3.\n",
        "**Input Data:** The text/data to process.\n",
        "\n",
        "\n",
        "4.\n",
        "**Output Constraints:** Format and length.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 4: Code]**"
      ],
      "metadata": {
        "id": "mwM1HsOgQgSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: Structured Email Summarizer\n",
        "\n",
        "# 1. DEFINE THE VARIABLES\n",
        "# [cite_start]This allows you to reuse the template for different inputs (Context Packing)[cite: 159].\n",
        "user_role = \"Expert HR Administrator\"\n",
        "task_instruction = \"Summarize the following grievance email. Extract the core issue and the requested resolution.\"\n",
        "constraints = \"\"\"\n",
        "- Format: Bullet points\n",
        "- Tone: Professional and Neutral\n",
        "- Length: Maximum 50 words\n",
        "- Do not use markdown formatting\n",
        "\"\"\"\n",
        "\n",
        "# [cite_start]The messy input data [cite: 185]\n",
        "input_text = \"\"\"\n",
        "Hi, I've been trying to get my laptop fixed for 3 weeks.\n",
        "IT keeps closing the ticket without fixing the screen.\n",
        "I can't work like this. I need a replacement immediately.\n",
        "\"\"\"\n",
        "\n",
        "# 2. BUILD THE PROMPT\n",
        "# We use f-strings to assemble the 4 parts clearly.\n",
        "structured_prompt = f\"\"\"\n",
        "# ROLE\n",
        "You are an {user_role}.\n",
        "\n",
        "# INSTRUCTION\n",
        "{task_instruction}\n",
        "\n",
        "# CONSTRAINTS\n",
        "{constraints}\n",
        "\n",
        "# INPUT DATA\n",
        "\\\"\\\"\\\"\n",
        "{input_text}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "# 3. GENERATE\n",
        "display_prompt(\"Exercise 1: Structure\", structured_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9eOJ0_GWQgSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **[Cell 5: Markdown]**\n",
        "\n",
        "## **Exercise 2: Chain-of-Thought (CoT) Reasoning**\n",
        "\n",
        "**Goal:** Prevent errors in calculation or logic by forcing the model to \"think\" before answering.\n",
        "\n",
        "We will use the **Zero-Shot CoT** technique by appending instructions to show reasoning steps.\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 6: Code]**"
      ],
      "metadata": {
        "id": "UevnhV4QQgSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: Expense Reconciliation Logic\n",
        "\n",
        "# 1. DEFINE INPUTS\n",
        "expense_policy = \"Company policy allows max $150 per person for client dinners.\"\n",
        "receipt_details = \"Receipt total: $500. Guests present: 2.\"\n",
        "\n",
        "# 2. BUILD CoT PROMPT\n",
        "# [cite_start]Note the specific instruction to \"think step-by-step\"[cite: 100, 110].\n",
        "cot_prompt = f\"\"\"\n",
        "# CONTEXT\n",
        "{expense_policy}\n",
        "\n",
        "# DATA\n",
        "{receipt_details}\n",
        "\n",
        "# INSTRUCTION\n",
        "Determine if this expense should be approved or rejected.\n",
        "\n",
        "# REASONING REQUIREMENT\n",
        "Explain your reasoning step-by-step before answering.\n",
        "Follow this format:\n",
        "Step 1: Calculate total allowed budget based on guest count.\n",
        "Step 2: Compare budget vs actual receipt.\n",
        "Step 3: State Final Decision (Approved/Rejected).\n",
        "\"\"\"\n",
        "\n",
        "display_prompt(\"Exercise 2: Chain of Thought\", cot_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "zobAhUZpQgSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **[Cell 7: Markdown]**\n",
        "\n",
        "## **Exercise 3: Few-Shot Prompting (JSON)**\n",
        "\n",
        "**Goal:** Force the AI to follow a strict business pattern by providing examples (\"shots\"). This is essential for business automation tasks like classification.\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 8: Code]**"
      ],
      "metadata": {
        "id": "fJgMuPm0QgSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: Support Ticket Classification\n",
        "\n",
        "# [cite_start]1. DEFINE EXAMPLES (Few-Shot) [cite: 151]\n",
        "# [cite_start]We provide 2 examples to teach the model the JSON format[cite: 98].\n",
        "examples = \"\"\"\n",
        "Example 1:\n",
        "Input: \"My account is locked and I can't access payroll!\"\n",
        "Output: {\"status\": \"Urgent\", \"category\": \"Access\"}\n",
        "\n",
        "Example 2:\n",
        "Input: \"Where can I find the holiday calendar?\"\n",
        "Output: {\"status\": \"General\", \"category\": \"Info\"}\n",
        "\"\"\"\n",
        "\n",
        "# 2. NEW TASK\n",
        "new_input = \"I suspect there is a fraudulent transaction on my corporate card ending in 4432.\"\n",
        "\n",
        "# 3. BUILD PROMPT\n",
        "few_shot_prompt = f\"\"\"\n",
        "# INSTRUCTION\n",
        "Classify the customer query into \"Urgent\" or \"General\" and assign a category.\n",
        "Response must be valid JSON.\n",
        "\n",
        "# EXAMPLES\n",
        "{examples}\n",
        "\n",
        "# TASK\n",
        "Input: \"{new_input}\"\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "display_prompt(\"Exercise 3: Few-Shot JSON\", few_shot_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9iudialIQgSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **[Cell 9: Markdown]**\n",
        "\n",
        "## **Exercise 4: ReAct (Reason + Act)**\n",
        "\n",
        "**Goal:** Simulate an Agentic workflow where the model plans an action before doing it.\n",
        "\n",
        "The ReAct pattern follows this loop: **Thought -> Action -> Observation**.\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 10: Code]**"
      ],
      "metadata": {
        "id": "s_EHUzOpQgSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: Agent Planning Prompt\n",
        "\n",
        "# [cite_start]1. DEFINE AGENT GOAL [cite: 80]\n",
        "agent_goal = \"I need to know if the engineering department is over budget for Q4 salaries.\"\n",
        "\n",
        "# [cite_start]2. BUILD REACT TEMPLATE [cite: 135]\n",
        "# This template forces the model to \"halt\" and wait for an observation (Action).\n",
        "react_prompt = f\"\"\"\n",
        "You are an autonomous HR Agent.\n",
        "To solve the user's request, you must use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take (available tools: [search_database, calculate_variance, send_email])\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Observation can repeat N times)\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "# USER REQUEST\n",
        "Question: {agent_goal}\n",
        "Thought:\n",
        "\"\"\"\n",
        "\n",
        "display_prompt(\"Exercise 4: ReAct Agent\", react_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "nepcK6MJQgSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **[Cell 11: Markdown]**\n",
        "\n",
        "## **Interactive Playground**\n",
        "\n",
        "Try changing the `my_task` and `my_role` variables below to generate your own \"Business Ready\" prompt template.\n",
        "\n",
        "---\n",
        "\n",
        "### **[Cell 12: Code]**"
      ],
      "metadata": {
        "id": "n_AyDc8tQgSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interactive Prompt Generator\n",
        "\n",
        "my_role = \"Senior Project Manager\" # @param {type:\"string\"}\n",
        "my_task = \"Draft a project kickoff email for the new AI migration project.\" # @param {type:\"string\"}\n",
        "my_constraints = \"- Tone: Exciting but realistic\\n- Include: Timeline, Team Roles, Next Steps\" # @param {type:\"string\"}\n",
        "\n",
        "custom_prompt = f\"\"\"\n",
        "# ROLE\n",
        "You are a {my_role}.\n",
        "\n",
        "# INSTRUCTION\n",
        "{my_task}\n",
        "\n",
        "# CONSTRAINTS\n",
        "{my_constraints}\n",
        "\n",
        "# OUTPUT FORMAT\n",
        "Please provide the output in a clear, copy-pasteable format.\n",
        "\"\"\"\n",
        "\n",
        "display_prompt(\"My Custom Template\", custom_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "td9UcG3cQgSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5MOBC1QJQgSD"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}